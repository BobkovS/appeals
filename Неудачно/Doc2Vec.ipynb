{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from utils import _tokenizer\n",
    "\n",
    "np.random.seed = 42\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные\n",
    "data = pd.read_csv(os.path.join('data', 'fully_prepared_data.csv'))\n",
    "\n",
    "# Шафлим датафрейм\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Разбиваем датафрейм на трейн и тест с отношением 0.9/0.1\n",
    "train_index = np.random.rand(len(data)) < 0.9\n",
    "train_data = data[train_index].reset_index(drop=True)\n",
    "test_data = data[~train_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function _tokenizer at 0x7fcaf34d02f0>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализируем и обучаем векторайзер\n",
    "vectorizer = TfidfVectorizer(tokenizer=_tokenizer)\n",
    "vectorizer.fit(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем X и Y\n",
    "X_train, X_test = vectorizer.transform(train_data.text), vectorizer.transform(test_data.text)\n",
    "X_train, X_test = pd.DataFrame(X_train.toarray()), pd.DataFrame(X_test.toarray())\n",
    "Y_category_train, Y_category_test = train_data.category, test_data.category\n",
    "Y_executor_train, Y_executor_test = train_data.executor, test_data.executor\n",
    "Y_theme_train, Y_theme_test = train_data.theme, test_data.theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем объекты XGBClassifier\n",
    "clf_category = LinearSVC()\n",
    "clf_executor = LinearSVC()\n",
    "clf_theme = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Учим модели первого уровня\n",
    "clf_category.fit(X_train, Y_category_train)\n",
    "clf_executor.fit(X_train, Y_executor_train)\n",
    "clf_theme.fit(X_train, Y_theme_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy of lvl1 models: category = 0.6781609195402298, executor = 0.6149425287356322, theme = 0.5344827586206896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Определяем точность моделей первого уровня\n",
    "clf_category_accuracy = clf_category.score(X_test, Y_category_test)\n",
    "clf_executor_accuracy = clf_executor.score(X_test, Y_executor_test)\n",
    "clf_theme_accuracy = clf_theme.score(X_test, Y_theme_test)\n",
    "\n",
    "print('Prediction accuracy of lvl1 models: category = {0}, executor = {1}, theme = {2}\\n'.format(clf_category_accuracy,\n",
    "                                                                                                 clf_executor_accuracy,\n",
    "                                                                                                 clf_theme_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = train_data.apply(\n",
    "    lambda r: TaggedDocument(words=(r['text']), tags=[r.category]), axis=1)\n",
    "test_tagged = test_data.apply(\n",
    "    lambda r: TaggedDocument(words=(r['text']), tags=[r.category]), axis=1)\n",
    "data_tagged = data.apply(\n",
    "    lambda r: TaggedDocument(words=(r['text']), tags=[r.category]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1786/1786 [00:00<00:00, 621301.07it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(data_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1786/1786 [00:00<00:00, 614925.87it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3004824.29it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3213653.77it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3374336.46it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 2106588.00it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3536839.92it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 1735239.04it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 2869026.02it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 2187161.15it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3502116.38it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3401919.59it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3476114.59it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3622353.45it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3408110.53it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3728734.17it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3610133.47it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3560374.02it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 2577779.40it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3493949.13it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3389604.95it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3779529.24it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 1576394.56it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 2897882.76it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3061310.56it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3323436.98it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 2845053.91it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3485819.89it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3406560.68it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3603187.56it/s]\n",
      "100%|██████████| 1786/1786 [00:00<00:00, 3563761.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 226 ms, total: 20.2 s\n",
      "Wall time: 6.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(data_tagged.values)]), total_examples=len(data_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector([doc.words], steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.26436781609195403\n",
      "Testing F1 score: 0.11055381400208987\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "\n",
    "logreg = LinearSVC()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
